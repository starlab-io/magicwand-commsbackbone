#!/usr/bin/python
import sys
import json
import datetime
import types

def parse_samples(filename):
    """
    Given a filename, parse out the stats generated by `vmstat`, which is a hella-wonky
    format, roughly like:

        procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- -----timestamp-----
         r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st                 UTC
         2  0      0 1191280  63460 723040    0    0    14    81  108  305  2  2 96  0  0 2016-07-05 16:23:55
         1  0      0 1178548  63464 724656    0    0     0   164  332 1770 43 55  2  0  0 2016-07-05 16:23:57

    For parsing and labeling purposes, we're using the MAN page definitions found at:

        http://linux.die.net/man/8/vmstat

    :param filename: VMSTAT log file
    :return: A list of dictionaries of performance data
    """
    samples = []
    test_duration = 0

    with open(filename) as file:
        for line in file:

            # only parse the lines that aren't headers
            if line.startswith("test-duration"):
                test_duration = int(line.strip().split(" ")[1])

            elif line.strip()[0] in "1234567890":

                # hooo-boy. This is admittedly ugly. So sorry. Because the timestamp has a space in it, we need
                # do shift some fields around and collapse white space
                cols = line.strip().split(" ")
                cols[-2] = cols[-2] + " " + cols[-1]
                cols = [ x for x in cols[:-1] if x != ""]

                samples.append(
                    {
                        "procs": {
                            "waiting": int(cols[0]),
                            "uninterruptable sleep": int(cols[1])
                        },
                        "memory": {
                            "swapped vmem": int(cols[2]),
                            "free": int(cols[3]),
                            "buffered": int(cols[4]),
                            "cache": int(cols[5])
                        },
                        "swap": {
                            "in": int(cols[6]),
                            "out": int(cols[7])
                        },
                        "io": {
                            "recv": int(cols[8]),
                            "sent": int(cols[9])
                        },
                        "system": {
                            "interrupts/sec": int(cols[10]),
                            "context switch/sec": int(cols[11])
                        },
                        "cpu": {
                            "user": int(cols[12]),
                            "system": int(cols[13]),
                            "idle": int(cols[14]),
                            "wait": int(cols[15]),
                            "stolen": int(cols[16])
                        },
                        "timestamp": "T".join(cols[17].split(" ")) + "Z"
                    }
                )

    return test_duration, samples


def dump_samples_csv(test_duration, samples, filename):
    """
    Output the samples of the reply rate to the given file. We're hand-jamming CSV
    because at this point we know the exact format of the data. This can only cause
    problems in the future.

    :param filename: Output file for performance data
    :return: None
    """
    with open(filename, 'w') as file:

        # We're trying to map a two layer dictionary to a one dimensional vector, with the
        # added complication of the default Python dictionaries being unordered. So, we build
        # a key list we can use
        write_keys = []
        for key, values in samples[0].items():
            if type(values) == types.DictType:
                for subkey, value in values.items():
                    write_keys.append((key, subkey))
            elif type(values) in types.StringTypes:
                write_keys.append((key,))

        # write the header row
        file.write(",".join(["-".join(write_key) for write_key in write_keys]) + "\n")

        for sample in samples:
            write_data = []

            # this is, again, a horrible horrible way to do this, but let's dive in and
            # auto build columns of data
            for write_key in write_keys:
                if len(write_key) == 2:
                    write_data.append(sample[write_key[0]][write_key[1]])
                elif len(write_key) == 1:
                    write_data.append(sample[write_key[0]])
            file.write(",".join([str(wd) for wd in write_data]) + "\n")


def dump_samples_json(test_duration, samples, filename):
    """
    Dump the test data to a sane JSON format that looks like:

        {
            "samples": [....],
            "collated_at": <created timestamp>,
            "min_timestamp": "MINUMUM OBSERVED TIMESTAMP",
            "max_timestamp": "MAXIMUM OBSERVED TIMESTAMP",
            "test_duration": #
        }

    :param samples:
    :param filename:
    :return:
    """
    with open(filename, "w") as file:
        json.dump(
            {
                "samples": samples,
                "collated_at": str(datetime.datetime.now()),
                "min_timestamp": samples[0]["timestamp"],
                "max_timestamp": samples[-1]["timestamp"],
                "test_duration": test_duration
            },
            file
        )


if __name__ == "__main__":

    input_file = "/var/log/apacheperf/performance.log"
    csv_output_file = "/var/log/apacheperf/performance.csv"
    json_output_file = "/var/log/apacheperf/performance.json"

    # poor mans arg parse
    if len(sys.argv) > 1:
        input_file = sys.argv[1]

    if len(sys.argv) > 2:
        csv_output_file = sys.argv[2]

    if len(sys.argv) > 3:
        json_output_file = sys.argv[3]

    test_duration, samples = parse_samples(input_file)
    dump_samples_csv(test_duration, samples, csv_output_file)
    dump_samples_json(test_duration, samples, json_output_file)
